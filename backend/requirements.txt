# Origo Backend Dependencies - Optimized for CPU-only deployment
# NOTE: PyTorch is installed separately via CPU-only index in Dockerfile
# This avoids downloading ~800MB of NVIDIA CUDA dependencies

# Essential AI and NLP Libraries (Currently using simulated calculations)
# transformers>=4.30.0,<5.0.0  # TODO: Uncomment when implementing real models
# torch>=2.0.0,<3.0.0  # TODO: Uncomment when implementing real models
# sentence-transformers>=2.2.0,<3.0.0  # TODO: Uncomment when implementing real models
# scikit-learn>=1.3.0,<2.0.0  # TODO: Uncomment when implementing real models
# nltk>=3.8,<4.0  # TODO: Uncomment when implementing real models
numpy>=1.24.0,<2.0.0  # Currently used in main.py

# Web Framework
fastapi>=0.100.0,<1.0.0
uvicorn[standard]>=0.23.0,<1.0.0

# Data Validation and HTTP
pydantic>=2.0.0,<3.0.0
requests>=2.31.0,<3.0.0

# PDF Generation
reportlab>=4.0.0,<5.0.0