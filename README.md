# Origo - AI Text Detection

**"Breaking down the signals of writing origin"**

Origo is a comprehensive web application that analyzes English text to estimate the probability that it was generated by artificial intelligence. The application provides explainable AI detection through multiple analysis heuristics with detailed breakdowns at word, sentence, and paragraph levels.

## ‚ö†Ô∏è Ethical Disclaimer

**Important:** AI-generated text detection is imperfect. This tool provides probabilistic signals ‚Äî not conclusive proof. It is meant to support human judgment, not replace it.

## üéØ Features

- **Multi-heuristic Analysis**: Combines perplexity, burstiness, semantic coherence, and n-gram similarity
- **Granular Insights**: Analysis at paragraph, sentence, and word levels
- **Interactive Visualization**: Color-coded highlights and tooltips
- **Responsive Design**: Works on desktop and tablet devices
- **Real-time Processing**: Fast analysis with progress indication
- **Word Impact Analysis**: Detailed breakdown of influential words

## üõ† Technology Stack

### Backend
- **Framework**: FastAPI (Python)
- **AI/ML**: Transformers, PyTorch, Sentence-BERT
- **NLP**: NLTK, spaCy, scikit-learn
- **Models**: GPT-2 (perplexity), all-MiniLM-L6-v2 (semantic analysis)

### Frontend
- **Framework**: React 18 with TypeScript
- **Build Tool**: Vite
- **UI**: Custom CSS with responsive design
- **HTTP Client**: Axios
- **Icons**: Lucide React

### Deployment
- **Containerization**: Docker & Docker Compose
- **Web Server**: Nginx (frontend proxy)
- **Cross-platform**: Windows, macOS, Linux support

## üìã Prerequisites

- **Node.js** 18+ (for frontend development)
- **Python** 3.11+ (for backend development)
- **Docker & Docker Compose** (for deployment)
- **Git** (for version control)

## üöÄ Quick Start with Docker

The fastest way to run Origo is using Docker Compose:

```bash
# Clone the repository
git clone <repository-url>
cd origo

# Start the application
docker-compose up --build

# Access the application
# Frontend: http://localhost:3000
# Backend API: http://localhost:8000
# API Documentation: http://localhost:8000/docs
```

## üíª Development Setup

### Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

# Start development server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev

# Build for production
npm run build
```

## üìñ API Documentation

### Analyze Text Endpoint

**POST** `/analyze`

Analyzes text for AI-generated content detection.

#### Request Body
```json
{
  "text": "Your text to analyze here..."
}
```

#### Response
```json
{
  "overall_score": 0.78,
  "global_scores": {
    "perplexity": 0.83,
    "burstiness": 0.72,
    "semantic_coherence": 0.65,
    "ngram_similarity": 0.89
  },
  "paragraphs": [
    {
      "text": "Paragraph text...",
      "score": 0.80,
      "sentences": [
        {
          "text": "Sentence text...",
          "score": 0.91,
          "words": [
            {"word": "thus", "score": 0.92}
          ]
        }
      ]
    }
  ],
  "word_analysis": {
    "unique_words": [
      {"word": "hence", "average_score": 0.91, "count": 3}
    ]
  }
}
```

### Other Endpoints

- **GET** `/` - API information
- **GET** `/health` - Health check
- **GET** `/docs` - Interactive API documentation

## üîß Analysis Components

### 1. Perplexity Analysis
- Uses GPT-2 language model
- Measures text predictability
- Lower perplexity suggests AI generation
- **Weight**: 40%

### 2. Burstiness Analysis
- Analyzes sentence length variation
- Examines syntactic complexity patterns
- Uniform patterns indicate AI text
- **Weight**: 20%

### 3. Semantic Coherence
- Uses Sentence-BERT embeddings
- Measures semantic flow consistency
- Extreme coherence may suggest AI
- **Weight**: 20%

### 4. N-gram Similarity
- Detects repetitive patterns
- Analyzes n-gram frequencies
- High repetition common in AI text
- **Weight**: 20%

## üé® User Interface

### Main Features
- **Text Input**: Large textarea with character/word count
- **Analysis Results**: Tabbed interface with multiple views
- **Score Visualization**: Circular progress indicators
- **Highlighted Text**: Color-coded analysis with tooltips
- **Word Table**: Sortable table with word-level insights

### Color Coding
- üü¢ **Green**: Low AI probability (0-40%)
- üü° **Yellow**: Medium AI probability (40-70%)
- üî¥ **Red**: High AI probability (70-100%)

## üê≥ Docker Deployment

### Production Deployment

```bash
# Build and start services
docker-compose up -d --build

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Update and restart
docker-compose pull
docker-compose up -d --build
```

### Environment Variables

Create `.env` file for custom configuration:

```env
# Backend
PYTHONPATH=/app
PYTHONUNBUFFERED=1

# Frontend
VITE_API_URL=http://localhost:8000
```

## üß™ Testing

### Backend Testing
```bash
cd backend
pytest tests/ -v
```

### Frontend Testing
```bash
cd frontend
npm test
```

### Integration Testing
```bash
# Start services
docker-compose up -d

# Test API endpoints
curl http://localhost:8000/health
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "This is a test sentence."}'
```

## üìä Performance Considerations

- **Model Loading**: Models are loaded once at startup
- **Request Timeout**: 2-minute timeout for analysis
- **Text Limits**: 10-50,000 character range
- **Memory Usage**: ~2GB RAM recommended for models
- **Processing Time**: 5-30 seconds depending on text length

## üöÄ Deployment Options

### Local Development
- Backend: `uvicorn main:app --reload`
- Frontend: `npm run dev`

### Docker Compose (Recommended)
- Full-stack deployment with one command
- Automatic service orchestration
- Health checks and restart policies

### Cloud Deployment
- **Backend**: Deploy to Heroku, Railway, or AWS
- **Frontend**: Deploy to Vercel, Netlify, or AWS S3
- **Full-stack**: Use Docker on DigitalOcean, AWS ECS, or Google Cloud Run

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## üìÑ License

This project is licensed under the MIT License. See LICENSE file for details.

## üôè Acknowledgments

- Hugging Face Transformers library
- Sentence-BERT for semantic analysis
- FastAPI framework
- React and Vite communities

## üìû Support

For questions or issues:
1. Check the GitHub Issues page
2. Review the API documentation at `/docs`
3. Ensure all prerequisites are installed
4. Verify Docker services are running

---

**Origo** - Bringing transparency to AI text detection through comprehensive analysis and clear visualization.